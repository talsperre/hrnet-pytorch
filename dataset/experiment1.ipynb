{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = \"/Users/shashanks./college/rrc/dataset/mpii/annot/train.json\"\n",
    "dataset_path = \"/Users/shashanks./college/rrc/dataset/mpii/images\"\n",
    "\n",
    "with open(annotation_path, 'r') as f:\n",
    "    annotation_json = json.load(f)\n",
    "\n",
    "pprint(annotation_json[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPII Flipped pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_pairs = [\n",
    "    [0, 5], # Right and Left Ankle\n",
    "    [1, 4], # Right and Left Knee\n",
    "    [2, 3], # Right and Left Hip\n",
    "    [10, 15], # Right and Left Wrist\n",
    "    [11, 14], # Right and Left Elbow\n",
    "    [12, 13] # Right and Left Shoulder \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display bbox image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4356\n",
    "img_path = os.path.join(dataset_path, annotation_json[idx]['image'])\n",
    "center = annotation_json[idx]['center']\n",
    "scale = annotation_json[idx]['scale']\n",
    "joints = np.array(annotation_json[idx]['joints'])\n",
    "visible_joints = np.array(annotation_json[idx]['joints_vis'])\n",
    "\n",
    "# Adjust center/scale slightly to avoid cropping limbs\n",
    "if center[0] != -1:\n",
    "    center[1] = center[1] + 15 * scale\n",
    "    scale = scale * 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = scale * 200\n",
    "x, y = int(center[0] - scale / 2.0), int(center[1] - scale / 2.0)\n",
    "w, h = int(scale), int(scale)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_bbox_image(img_path):\n",
    "    img = cv2.imread(img_path)[:,:,::-1] #OpenCV uses BGR channels\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax1 = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    ax1.imshow(img)\n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    plt.scatter([x], [y])\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax1.add_patch(rect)\n",
    "    plt.show()\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = disp_bbox_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crop(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        img, keypoints, visible_keypoints, scale = sample[\"image\"], sample[\"keypoints\"], sample[\"visible_keypoints\"], sample[\"scale\"]\n",
    "        x, y = int(center[0] - scale / 2.0), int(center[1] - scale / 2.0)\n",
    "        # Row, cols are interchanged in image and numpy arrays\n",
    "        row, col = y, x\n",
    "        cropped_image = img[row:row + h, col:col + w]\n",
    "        \n",
    "        for i in range(keypoints.shape[0]):\n",
    "            if keypoints[i, 0] < x or keypoints[i, 0] > x + w or keypoints[i, 1] < y or keypoints[i, 1] > y + h:\n",
    "                visible_keypoints[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row, col = y, x\n",
    "# cropped_image = deepcopy(img[row:row + h, col:col + w])\n",
    "# plt.imshow(cropped_image)\n",
    "\n",
    "row, col = y, x\n",
    "cropped_image = img[row:row + h, col:col + w]\n",
    "plt.imshow(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Keypoints image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_keypoints_image(img, keypoints):    \n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    ax1 = fig.add_subplot(1, 1, 1)\n",
    "    keypoints_num = list(range(len(keypoints)))\n",
    "    ax1.imshow(img)\n",
    "    ax1.scatter(keypoints[:, 0], keypoints[:, 1])\n",
    "    \n",
    "    for i, txt in enumerate(keypoints_num):\n",
    "        ax1.annotate(txt, (keypoints[i, 0], keypoints[i, 1]), c='w')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_keypoints_image(img, joints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    \"image\": img, \n",
    "    \"keypoints\": joints,\n",
    "    \"visible_keypoints\": visible_joints\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Flip Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHorizontalFlip(object):\n",
    "    def __init__(self, prob=0.5):\n",
    "        assert prob >= 0 and prob <= 1, \"Invalid probability\"\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img, keypoints, visible_keypoints = sample[\"image\"], sample[\"keypoints\"], sample[\"visible_keypoints\"]\n",
    "        img_shape = np.array(img.shape[:2])\n",
    "        # Get the centerpoints, we flip rows and columns as we are dealing with matrices\n",
    "        img_center = img_shape[::-1] / 2\n",
    "        \n",
    "        if np.random.rand() < self.prob:\n",
    "            img =  img[:, ::-1, :] # Flip the image\n",
    "            keypoints[:, 0] += 2 * (img_center[0] - keypoints[:, 0])\n",
    "            \n",
    "            for pair in flip_pairs:\n",
    "                idx_1, idx_2 = pair\n",
    "                keypoints[idx_1, :], keypoints[idx_2, :] = keypoints[idx_2, :], keypoints[idx_1, :].copy()\n",
    "                visible_keypoints[idx_1], visible_keypoints[idx_2] = visible_keypoints[idx_2], visible_keypoints[idx_1].copy()\n",
    "\n",
    "            updated_sample = {\n",
    "                \"image\": img, \n",
    "                \"keypoints\": keypoints, \n",
    "                \"visible_keypoints\": visible_keypoints\n",
    "            }\n",
    "            return updated_sample\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RandomHorizontalFlip()\n",
    "updated_sample = r(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_keypoints_image(updated_sample[\"image\"], updated_sample[\"keypoints\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    \"image\": img, \n",
    "    \"keypoints\": joints,\n",
    "    \"visible_keypoints\": visible_joints\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomScale(object):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale: float or tuple(float)\n",
    "        if **float**, the image is scaled by a factor drawn \n",
    "        randomly from a range (1 - `scale` , 1 + `scale`). If **tuple**,\n",
    "        the `scale` is drawn randomly from values specified by the \n",
    "        tuple\n",
    "    diff: bool\n",
    "        if **true**, the x & y dimensions are scaled equally, else they \n",
    "        are scaled separately.    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, scale, diff):\n",
    "        self.scale = scale\n",
    "        self.diff = diff\n",
    "        if type(self.scale) != tuple:\n",
    "            self.scale = max((-1, -self.scale), self.scale)\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        img, keypoints, visible_keypoints = sample[\"image\"], sample[\"keypoints\"], sample[\"visible_keypoints\"]\n",
    "        img_shape = img.shape\n",
    "        if self.diff:\n",
    "            scale_x = np.random.uniform(*self.scale)\n",
    "            scale_y = np.random.uniform(*self.scale)\n",
    "        else:\n",
    "            scale_x = np.random.uniform(*self.scale)\n",
    "            scale_y = scale_x\n",
    "        \n",
    "        rescale_x = 1 + scale_x\n",
    "        rescale_y = 1 + scale_y\n",
    "        \n",
    "        updated_img = cv2.resize(img, fx=rescale_x, fy=rescale_y)\n",
    "        updated_keypoints = deepcopy(keypoints)\n",
    "        updated_keypoints[:, 0] = updated_keypoints[:, 0] * rescale_x\n",
    "        updated_keypoints[:, 1] = updated_keypoints[:, 1] * rescale_y\n",
    "        \n",
    "        canvas = np.zeros(img_shape, dtype=np.uint8)\n",
    "        # X and Y axes are flipped in arrays and images\n",
    "        x_lim = np.min(img_shape[1], updated_img.shape[1])\n",
    "        y_lim = np.min(img_shape[0], updated_img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, keypoints, visible_keypoints = updated_sample[\"image\"], updated_sample[\"keypoints\"], updated_sample[\"visible_keypoints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints1 = deepcopy(keypoints)\n",
    "keypoints1[:, 0] = keypoints1[:, 0] * 1.35\n",
    "keypoints1[:, 1] = keypoints1[:, 1] * 2.25\n",
    "\n",
    "# keypoints1[:, 0] = keypoints1[:, 0] * 2.25\n",
    "# keypoints1[:, 1] = keypoints1[:, 1] * 1.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints1[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updated_img = cv2.resize(img, None, fx=1.35, fy=2.25)\n",
    "\n",
    "plt.scatter(keypoints1[7, 0], keypoints1[7, 1])\n",
    "\n",
    "plt.imshow(updated_img)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomScale(object):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale: float or tuple(float)\n",
    "        if **float**, the image is scaled by a factor drawn \n",
    "        randomly from a range (1 - `scale` , 1 + `scale`). If **tuple**,\n",
    "        the `scale` is drawn randomly from values specified by the \n",
    "        tuple\n",
    "    diff: bool\n",
    "        if **true**, the x & y dimensions are scaled equally, else they \n",
    "        are scaled separately.\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=0.25, diff=False):\n",
    "        self.scale = scale\n",
    "        if type(scale) == tuple:\n",
    "            assert len(self.scale) == 2, \"Invalid range\"\n",
    "            assert self.scale[0] > -1, \"Scale factor can't be less than -1\"\n",
    "            assert self.scale[1] > -1, \"Scale factor can't be less than -1\"\n",
    "        else:\n",
    "            assert self.scale > 0, \"Please input a positive float\"\n",
    "            self.scale = (max(-1, -self.scale), self.scale)\n",
    "        self.diff = diff\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        img, keypoints, visible_keypoints = sample[\"image\"], sample[\"keypoints\"], sample[\"visible_keypoints\"]\n",
    "        if self.diff:\n",
    "            scale_x = np.random.uniform(*self.scale)\n",
    "            scale_y = np.random.uniform(*self.scale)\n",
    "        else:\n",
    "            scale_x = np.random.uniform(*self.scale)\n",
    "            scale_y = scale_x\n",
    "        \n",
    "        resize_scale_x = 1 + scale_x\n",
    "        resize_scale_y = 1 + scale_y\n",
    "        \n",
    "        img = cv2.resize(img, None, fx=resize_scale_x, fy=resize_scale_y)\n",
    "        keypoints[:, 0] *= resize_scale_x\n",
    "        keypoints[:, 1] *= resize_scale_y\n",
    "        \n",
    "        updated_sample = {\n",
    "            \"image\": img,\n",
    "            \"keypoints\": keypoints,\n",
    "            \"visible_keypoints\": visible_keypoints\n",
    "        }\n",
    "        return updated_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = RandomScale((0.65, 1.30))\n",
    "updated_sample = s(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_keypoints_image(updated_sample[\"image\"], updated_sample[\"keypoints\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
